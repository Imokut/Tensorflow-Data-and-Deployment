{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-2-public/blob/adding_C2/C2/W1/assignment/C2_W1_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zX4Kg8DUTKWO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Za8-Nr5k11fh"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "Eq10uEbw0E4l",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06ndLauQxiQm"
   },
   "source": [
    "# Train Your Own Model and Convert It to TFLite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ka96-ajYzxVU"
   },
   "source": [
    "This notebook uses the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
    "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n",
    "\n",
    "Fashion MNIST is intended as a drop-in replacement for the classic [MNIST](http://yann.lecun.com/exdb/mnist/) dataset—often used as the \"Hello, World\" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc.) in a format identical to that of the articles of clothing we'll use here.\n",
    "\n",
    "This uses Fashion MNIST for variety, and because it's a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code.\n",
    "\n",
    "We will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from TensorFlow. Import and load the Fashion MNIST data directly from TensorFlow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjOAfhgd__Sp"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Bp_nvHnh_tDo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pfyZKowNAQ4j",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 16:54:46.282389: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-31 16:54:46.774706: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-31 16:54:46.776542: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-31 16:54:48.483129: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Using TensorFlow Version: 2.12.0\n",
      "WARNING:tensorflow:From /tmp/ipykernel_83/3691826295.py:11: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "• GPU Device Not Found. Running on CPU\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "\n",
    "print('\\u2022 Using TensorFlow Version:', tf.__version__)\n",
    "print('\\u2022 GPU Device Found.' if tf.test.is_gpu_available() else '\\u2022 GPU Device Not Found. Running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tadPBTEiAprt"
   },
   "source": [
    "# Download Fashion MNIST Dataset\n",
    "\n",
    "We will use TensorFlow Datasets to load the Fashion MNIST dataset. \n",
    "\n",
    "**IMPORTANT NOTE:** The tfds `ALL` split has been deprecated in the latest TensorFlow version. If you are running this file on Coursera, kindly use the code:\n",
    "```python\n",
    "splits = tfds.Split.ALL.subsplit(weighted=(80, 10, 10))\n",
    "\n",
    "filePath = f\"{getcwd()}/../tmp2/\"\n",
    "splits, info = tfds.load('fashion_mnist', with_info=True, as_supervised=True, split=splits, data_dir=filePath)\n",
    "\n",
    "(train_examples, validation_examples, test_examples) = splits\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "If you are running the file on your local machine with the latest TensorFlow version or using Google Colab, comment out the above code and uncomment this code:\n",
    "\n",
    "```python\n",
    "(train_examples, validation_examples, test_examples), info = tfds.load('fashion_mnist', \n",
    "                                                                       with_info=True, \n",
    "                                                                       as_supervised=True, \n",
    "                                                                       split=['train[:80%]',\n",
    "                                                                              'train[80%:90%]',\n",
    "                                                                              'train[90%:]'])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XcNwi6nFKneZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# splits = tfds.Split.ALL.subsplit(weighted=(80, 10, 10))\n",
    "\n",
    "# filePath = f\"{getcwd()}/../tmp2/\"\n",
    "# splits, info = tfds.load('fashion_mnist', with_info=True, as_supervised=True, split=splits, data_dir=filePath)\n",
    "\n",
    "# (train_examples, validation_examples, test_examples) = splits\n",
    "\n",
    "(train_examples, validation_examples, test_examples), info = tfds.load('fashion_mnist', \n",
    "                                                                       with_info=True, \n",
    "                                                                       as_supervised=True, \n",
    "                                                                       split=['train[:80%]',\n",
    "                                                                              'train[80%:90%]',\n",
    "                                                                              'train[90%:]'])\n",
    "\n",
    "num_examples = info.splits['train'].num_examples\n",
    "num_classes = info.features['label'].num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-Q4C7WILELz"
   },
   "source": [
    "The class names are not included with the dataset, so we will specify them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-eAv71FRm4JE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt_top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hXe6jNokqX3_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a labels.txt file with the class names\n",
    "with open('labels.txt', 'w') as f:\n",
    "    f.write('\\n'.join(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iubWCThbdN8K",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The images in the dataset are 28 by 28 pixels.\n",
    "IMG_SIZE = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAkuq0V0Aw2X"
   },
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5SIivkunKCC"
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BwyhsyGydHDl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Write a function to normalize the images.\n",
    "\n",
    "def format_example(image, label):\n",
    "    # Cast image to float32\n",
    "    image = tf.cast(image, tf.float32)  # YOUR CODE HERE\n",
    "        \n",
    "    # Normalize the image in the range [0, 1]\n",
    "    image = image/255.0 # YOUR CODE HERE\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HAlBlXOUMwqe"
   },
   "outputs": [],
   "source": [
    "# Specify the batch size\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JM4HfIJtnNEk"
   },
   "source": [
    "## Create Datasets From Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "uxe2I3oxLDhq"
   },
   "outputs": [],
   "source": [
    "# Create Datasets\n",
    "train_batches = train_examples.cache().shuffle(num_examples//4).batch(BATCH_SIZE).map(format_example).prefetch(1)\n",
    "validation_batches = validation_examples.cache().batch(BATCH_SIZE).map(format_example)\n",
    "test_batches = test_examples.batch(1).map(format_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-topQaOm_LM"
   },
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dJbV-jNLEL2"
   },
   "source": [
    "```\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
    "_________________________________________________________________\n",
    "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 3872)              0         \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 64)                247872    \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 10)                650       \n",
    "=================================================================\n",
    "Total params: 253,322\n",
    "Trainable params: 253,322\n",
    "Non-trainable params: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "kDqcwksFB1bh"
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Build and compile the model shown in the previous cell.\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # Set the input shape to (28, 28, 1), kernel size=3, filters=16 and use ReLU activation,\n",
    "    tf.keras.layers.Conv2D(16, 3, input_shape=(28, 28, 1), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    # Set the number of filters to 32, kernel size to 3 and use ReLU activation \n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    # Flatten the output layer to 1 dimension\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Add a fully connected layer with 64 hidden units and ReLU activation\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    # Attach a final softmax classification head\n",
    "    tf.keras.layers.Dense(10, activation='softmax')])\n",
    "\n",
    "# Set the appropriate loss function and use accuracy as your metric\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEMOz-LDnxgD"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "JGlNoRtzCP4_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "187/188 [============================>.] - ETA: 0s - loss: 0.6112 - accuracy: 0.7949"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 17:15:16.632062: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-31 17:15:16.632705: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 12s 55ms/step - loss: 0.6111 - accuracy: 0.7949 - val_loss: 0.4100 - val_accuracy: 0.8508\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.3783 - accuracy: 0.8671 - val_loss: 0.3616 - val_accuracy: 0.8712\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.3316 - accuracy: 0.8828 - val_loss: 0.3254 - val_accuracy: 0.8847\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.2986 - accuracy: 0.8933 - val_loss: 0.3030 - val_accuracy: 0.8908\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.2824 - accuracy: 0.8983 - val_loss: 0.2958 - val_accuracy: 0.8957\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.2587 - accuracy: 0.9071 - val_loss: 0.2737 - val_accuracy: 0.9032\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.2427 - accuracy: 0.9110 - val_loss: 0.2525 - val_accuracy: 0.9085\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.2277 - accuracy: 0.9181 - val_loss: 0.2449 - val_accuracy: 0.9102\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.2180 - accuracy: 0.9208 - val_loss: 0.2526 - val_accuracy: 0.9032\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.2038 - accuracy: 0.9264 - val_loss: 0.2424 - val_accuracy: 0.9110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f71973bdb80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_batches, \n",
    "          epochs=10,\n",
    "          validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZT9-7w9n4YO"
   },
   "source": [
    "# Exporting to TFLite\n",
    "\n",
    "You will now save the model to TFLite. We should note, that you will probably see some warning messages when running the code below. These warnings have to do with software updates and should not cause any errors or prevent your code from running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9dq78KBkCV2_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/1/assets\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE: Use the tf.saved_model API to save your model in the SavedModel format. \n",
    "export_dir = 'saved_model/1'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "tf.saved_model.save(model, export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cellView": "form",
    "id": "EDGiYrBdE6fl"
   },
   "outputs": [],
   "source": [
    "#@title Select mode of optimization\n",
    "mode = \"Speed\" #@param [\"Default\", \"Storage\", \"Speed\"]\n",
    "\n",
    "if mode == 'Storage':\n",
    "    optimization = tf.lite.Optimize.OPTIMIZE_FOR_SIZE\n",
    "elif mode == 'Speed':\n",
    "    optimization = tf.lite.Optimize.OPTIMIZE_FOR_LATENCY\n",
    "else:\n",
    "    optimization = tf.lite.Optimize.DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "RbcS9C00CzGe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Optimization option OPTIMIZE_FOR_LATENCY is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_LATENCY is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_LATENCY is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "2023-05-31 17:29:51.908320: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-05-31 17:29:51.908356: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-05-31 17:29:51.909575: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: saved_model/1\n",
      "2023-05-31 17:29:51.911481: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-05-31 17:29:51.911501: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: saved_model/1\n",
      "2023-05-31 17:29:51.915911: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
      "2023-05-31 17:29:51.917165: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-05-31 17:29:51.964297: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: saved_model/1\n",
      "2023-05-31 17:29:51.978728: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 69156 microseconds.\n",
      "2023-05-31 17:29:52.040937: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE: Use the TFLiteConverter SavedModel API to initialize the converter\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir) # YOUR CODE HERE\n",
    "\n",
    "# Set the optimzations\n",
    "converter.optimizations = [optimization] # YOUR CODE HERE\n",
    "\n",
    "# Invoke the converter to finally generate the TFLite model\n",
    "tflite_model = converter.convert() # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "q5PWCDsTC3El"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259816"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_file = pathlib.Path('./model.tflite')\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SR6wFcQ1Fglm"
   },
   "source": [
    "# Test the Model with TFLite Interpreter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "rKcToCBEC-Bu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "E8EpFpIBFkq8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 17:32:30.885937: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-31 17:32:30.886511: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-31 17:32:30.973369: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Gather results for the randomly sampled test images\n",
    "predictions = []\n",
    "test_labels = []\n",
    "test_images = []\n",
    "\n",
    "for img, label in test_batches.take(50):\n",
    "    interpreter.set_tensor(input_index, img)\n",
    "    interpreter.invoke()\n",
    "    predictions.append(interpreter.get_tensor(output_index))\n",
    "    test_labels.append(label[0])\n",
    "    test_images.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cellView": "form",
    "id": "kSjTmi05Tyod"
   },
   "outputs": [],
   "source": [
    "#@title Utility functions for plotting\n",
    "# Utilities for plotting\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    img = np.squeeze(img)\n",
    "    \n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    \n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    \n",
    "    if predicted_label == true_label.numpy():\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                         100*np.max(predictions_array),\n",
    "                                         class_names[true_label]), color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(list(range(10)), class_names, rotation='vertical')\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array[0], color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array[0])\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cellView": "form",
    "id": "ZZwg0wFaVXhZ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Visualize the outputs { run: \"auto\" }\n",
    "index = 12 #@param {type:\"slider\", min:1, max:50, step:1}\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(index, predictions, test_labels, test_images)\n",
    "plt.show()\n",
    "plot_value_array(index, predictions, test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "076bo3FMpRDb"
   },
   "source": [
    "# Download the TFLite Model and Assets\n",
    "\n",
    "If you are running this notebook in a Colab, you can run the cell below to download the tflite model and labels to your local disk.\n",
    "\n",
    "**Note**: If the files do not download when you run the cell, try running the cell a second time. Your browser might prompt you to allow multiple files to be downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "XsPXqPlgZPjE"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "    \n",
    "    files.download(tflite_model_file)\n",
    "    files.download('labels.txt')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8t7_jRiz9Vw"
   },
   "source": [
    "# Prepare the Test Images for Download (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Fi09nIps0gBu"
   },
   "outputs": [],
   "source": [
    "!mkdir -p test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "sF7EZ63J0hZs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 17:32:52.972332: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-31 17:32:52.973110: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "2023-05-31 17:32:53.070748: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for index, (image, label) in enumerate(test_batches.take(50)):\n",
    "    image = tf.cast(image * 255.0, tf.uint8)\n",
    "    image = tf.squeeze(image).numpy()\n",
    "    pil_image = Image.fromarray(image)\n",
    "    pil_image.save('test_images/{}_{}.jpg'.format(class_names[label[0]].lower(), index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "uM35O-uv0iWS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ankle boot_10.jpg'   coat_40.jpg       sandal_19.jpg\t sneaker_43.jpg\n",
      "'ankle boot_32.jpg'   coat_46.jpg       sandal_2.jpg\t t-shirt_top_1.jpg\n",
      "'ankle boot_4.jpg'    coat_48.jpg       sandal_39.jpg\t t-shirt_top_15.jpg\n",
      " bag_16.jpg\t      dress_12.jpg      shirt_27.jpg\t t-shirt_top_18.jpg\n",
      " bag_17.jpg\t      dress_29.jpg      shirt_33.jpg\t t-shirt_top_21.jpg\n",
      " bag_23.jpg\t      dress_37.jpg      shirt_5.jpg\t t-shirt_top_47.jpg\n",
      " bag_3.jpg\t      dress_45.jpg      sneaker_13.jpg\t t-shirt_top_8.jpg\n",
      " bag_34.jpg\t      dress_6.jpg       sneaker_24.jpg\t trouser_20.jpg\n",
      " bag_36.jpg\t      pullover_28.jpg   sneaker_25.jpg\t trouser_22.jpg\n",
      " bag_7.jpg\t      pullover_44.jpg   sneaker_26.jpg\t trouser_35.jpg\n",
      " coat_11.jpg\t      pullover_9.jpg    sneaker_38.jpg\t trouser_49.jpg\n",
      " coat_30.jpg\t      sandal_0.jpg      sneaker_41.jpg\n",
      " coat_31.jpg\t      sandal_14.jpg     sneaker_42.jpg\n"
     ]
    }
   ],
   "source": [
    "!ls test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "aR20r4qW0jVm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: zip: not found\n"
     ]
    }
   ],
   "source": [
    "!zip -qq fmnist_test_images.zip -r test_images/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgJ0fVklLEL9"
   },
   "source": [
    "If you are running this notebook in a Colab, you can run the cell below to download the Zip file with the images to your local disk. \n",
    "\n",
    "**Note**: If the Zip file does not download when you run the cell, try running the cell a second time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "tjk4537X0kWN"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    files.download('fmnist_test_images.zip')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "C2_W1_Assignment.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
